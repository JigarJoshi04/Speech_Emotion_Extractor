{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotion_Analyzer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ZaKVTW0lL4YltMfwA31NBuCwnuefzp3d",
      "authorship_tag": "ABX9TyMbdeMHdvto9wPJu6I4QM4a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JigarJoshi04/Speech_Emotion_Extractor/blob/master/Emotion_Analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED9m1nc3XNSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "f0376228-bfbb-4587-e009-0b9c4a1c747b"
      },
      "source": [
        "pip install soundfile"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting soundfile\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n",
            "Installing collected packages: soundfile\n",
            "Successfully installed soundfile-0.10.3.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDLMTjbP_J4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import soundfile\n",
        "import numpy as np\n",
        "import librosa\n",
        "import glob\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xiSE2tBF5Lo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "int2emotion = {\n",
        "    \"01\": \"neutral\",\n",
        "    \"02\": \"calm\",\n",
        "    \"03\": \"happy\",\n",
        "    \"04\": \"sad\",\n",
        "    \"05\": \"angry\",\n",
        "    \"06\": \"fearful\",\n",
        "    \"07\": \"disgust\",\n",
        "    \"08\": \"surprised\"\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqipCZxsHDX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AVAILABLE_EMOTIONS = {\n",
        "    \"angry\",\n",
        "    \"sad\",\n",
        "    \"neutral\",\n",
        "    \"happy\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uiLqURnHGHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_feature(file_name, **kwargs):\n",
        "    \"\"\"\n",
        "    Extract feature from audio file `file_name`\n",
        "        Features supported:\n",
        "            - MFCC (mfcc)\n",
        "            - Chroma (chroma)\n",
        "            - MEL Spectrogram Frequency (mel)\n",
        "            - Contrast (contrast)\n",
        "            - Tonnetz (tonnetz)\n",
        "        e.g:\n",
        "        `features = extract_feature(path, mel=True, mfcc=True)`\n",
        "    \"\"\"\n",
        "    mfcc = kwargs.get(\"mfcc\")\n",
        "    chroma = kwargs.get(\"chroma\")\n",
        "    mel = kwargs.get(\"mel\")\n",
        "    contrast = kwargs.get(\"contrast\")\n",
        "    tonnetz = kwargs.get(\"tonnetz\")\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate = sound_file.samplerate\n",
        "        if chroma or contrast:\n",
        "            stft = np.abs(librosa.stft(X))\n",
        "        result = np.array([])\n",
        "        if mfcc:\n",
        "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "            result = np.hstack((result, mfccs))\n",
        "        if chroma:\n",
        "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "            result = np.hstack((result, chroma))\n",
        "        if mel:\n",
        "            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "            result = np.hstack((result, mel))\n",
        "        if contrast:\n",
        "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
        "            result = np.hstack((result, contrast))\n",
        "        if tonnetz:\n",
        "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
        "            result = np.hstack((result, tonnetz))\n",
        "    return result\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZv-PW-RHRah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(test_size=0.2):\n",
        "    X, y = [], []\n",
        "    for file in glob.glob(\"/content/drive/My Drive/Ravdess database/Actor_*/*.wav\"):\n",
        "        print(file)\n",
        "        # get the base name of the audio file\n",
        "        if(file == \"/content/drive/My Drive/Ravdess database/Actor_02/03-01-01-01-01-01-02.wav\"):\n",
        "          break\n",
        "        basename = os.path.basename(file)\n",
        "        # get the emotion label\n",
        "        emotion = int2emotion[basename.split(\"-\")[2]]\n",
        "        # we allow only AVAILABLE_EMOTIONS we set\n",
        "        if emotion not in AVAILABLE_EMOTIONS:\n",
        "            continue\n",
        "        # extract speech features\n",
        "        features = extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
        "        # add to data\n",
        "        X.append(features)\n",
        "        y.append(emotion)\n",
        "    # split the data to training and testing and return it\n",
        "    return train_test_split(np.array(X), y, test_size=test_size, random_state=7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaoDObKkIlOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCqYzHqVIxi0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "430324a6-b6a1-41f7-fc8c-df30c1d284ec"
      },
      "source": [
        "X_train, X_test, y_train, y_test = load_data(test_size=0.25)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-02-01-01-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-03-01-01-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-04-01-01-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-03-01-02-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-02-01-02-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-02-01-01-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-02-02-01-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-03-02-02-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-03-01-02-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-03-01-01-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-01-01-01-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-02-01-02-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-02-02-01-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-03-02-01-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-01-01-01-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-02-02-02-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-01-01-02-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-03-02-01-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-02-02-02-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-03-02-02-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-01-01-02-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-08-01-01-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-07-01-01-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-06-01-01-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-05-02-01-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-05-02-01-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-06-02-01-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-07-02-02-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-08-01-02-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-05-01-02-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-06-01-02-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-07-01-02-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-08-02-02-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-04-02-02-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-07-02-01-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-06-02-02-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-05-01-01-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-06-01-01-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-05-02-02-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-08-01-01-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-06-01-02-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-04-02-02-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-04-01-02-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-04-01-01-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-06-02-01-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-05-01-02-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-08-02-01-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-07-01-02-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-08-02-02-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-08-02-01-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-07-01-01-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-05-02-02-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-07-02-01-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-04-02-01-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-04-02-01-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-05-01-01-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-08-01-02-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-06-02-02-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-07-02-02-01-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_01/03-01-04-01-02-02-01.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-01-01-01-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-01-01-02-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-01-01-02-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-01-01-01-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-08-01-01-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-05-01-01-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-03-02-02-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-02-02-02-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-05-01-02-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-06-02-01-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-08-01-02-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-02-02-02-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-08-01-02-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-08-02-01-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-04-01-01-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-05-02-02-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-07-02-01-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-03-02-01-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-06-02-02-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-04-01-02-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-07-01-02-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-06-02-01-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-06-02-02-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-07-01-01-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-03-01-02-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-04-02-02-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-02-02-01-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-07-01-02-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-03-02-02-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-02-01-01-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-03-01-01-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-06-01-01-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-05-01-02-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-08-02-01-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-08-02-02-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-06-01-02-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-06-01-02-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-07-02-01-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-08-02-02-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-05-02-02-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-04-02-02-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-05-01-01-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-02-02-01-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-04-02-01-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-03-01-01-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-02-01-02-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-03-01-02-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-07-01-01-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-03-02-01-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-07-02-02-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-06-01-01-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-02-01-02-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-07-02-02-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-02-01-01-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-05-02-01-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-04-01-02-02-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-05-02-01-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-08-01-01-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-04-01-01-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_07/03-01-04-02-01-01-07.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_02/03-01-03-01-01-01-02.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_02/03-01-03-01-02-01-02.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_02/03-01-02-02-01-02-02.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_02/03-01-02-02-02-02-02.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_02/03-01-02-01-01-01-02.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_02/03-01-02-01-02-02-02.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_02/03-01-01-01-01-02-02.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_02/03-01-01-01-02-01-02.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_02/03-01-03-02-01-02-02.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_02/03-01-02-01-02-01-02.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_02/03-01-03-02-01-01-02.wav\n",
            "/content/drive/My Drive/Ravdess database/Actor_02/03-01-01-01-01-01-02.wav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HBuVNLPJH7l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "ec02b249-dad9-450a-ca41-e6bf75dd984d"
      },
      "source": [
        "print(\"[+] Number of training samples:\", X_train.shape[0])\n",
        "print(\"[+] Number of testing samples:\", X_test.shape[0])\n",
        "print(\"[+] Number of features:\", X_train.shape[1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[+] Number of training samples: 46\n",
            "[+] Number of testing samples: 16\n",
            "[+] Number of features: 180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXQ5ChVUJTOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_params = {\n",
        "    'alpha': 0.01,\n",
        "    'batch_size': 256,\n",
        "    'epsilon': 1e-08, \n",
        "    'hidden_layer_sizes': (300,), \n",
        "    'learning_rate': 'adaptive', \n",
        "    'max_iter': 500, \n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KDbj51OJWV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MLPClassifier(**model_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15NZKgYKJaEV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "c20e15ae-a4e8-47c6-f8d6-194001bb1dc7"
      },
      "source": [
        "print(\"[*] Training the model...\")\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[*] Training the model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:352: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
            "  warnings.warn(\"Got `batch_size` less than 1 or larger than \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.01, batch_size=256, beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(300,), learning_rate='adaptive',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=500,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5S7mzrdJdMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZFy_Gsjv3gZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_load_data(test_size=1):\n",
        "    X, y = [], []\n",
        "    # for file in glob.glob(\"/content/drive/My Drive/Ravdess database/Actor_*/*.wav\"):\n",
        "    file = \"/content/drive/My Drive/Ravdess database/Actor_08/03-01-01-01-01-01-08.wav\"\n",
        "    print(file)\n",
        "        # # get the base name of the audio file\n",
        "        # if(file == \"/content/drive/My Drive/Ravdess database/Actor_02/03-01-01-01-01-01-02.wav\"):\n",
        "        #   break\n",
        "    basename = os.path.basename(file)\n",
        "        # # get the emotion label\n",
        "    emotion = int2emotion[basename.split(\"-\")[2]]\n",
        "        # we allow only AVAILABLE_EMOTIONS we set\n",
        "    # if emotion not in AVAILABLE_EMOTIONS:\n",
        "    #     continue\n",
        "    # extract speech features\n",
        "    features = extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
        "    # add to data\n",
        "    X.append(features)\n",
        "    y.append(emotion)\n",
        "    # split the data to training and testing and return it\n",
        "    return train_test_split(np.array(X), y, test_size=test_size, random_state=7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhQ0UFa7yJ9J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "30d2844c-fd9e-42ae-a03d-78853f6a25f7"
      },
      "source": [
        "my_test_feature = []\n",
        "my_test_label =[]\n",
        "file = \"/content/drive/My Drive/Ravdess database/Actor_08/03-01-01-01-01-01-08.wav\"\n",
        "print(file)\n",
        "basename = os.path.basename(file)\n",
        "# # get the emotion label\n",
        "emotion = int2emotion[basename.split(\"-\")[2]]\n",
        "features = extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
        "my_test_feature.append(features)\n",
        "my_test_label.append(emotion)\n",
        "print(my_test_label)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Ravdess database/Actor_08/03-01-01-01-01-01-08.wav\n",
            "['neutral']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pHLmL8zytL7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e03ee5a2-e856-447d-c74a-78cdddd0374a"
      },
      "source": [
        "my_y_pred =model.predict(my_test_feature)\n",
        "print(my_y_pred)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['neutral']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0RnUEFOxLPQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "8a419fbf-c8d7-48d8-8642-cee01ecfa11e"
      },
      "source": [
        "my_X_test, my_y_test = my_load_data(test_size=0.9)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Ravdess database/Actor_08/03-01-01-01-01-01-08.wav\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-bf933e69787f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_X_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_y_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_load_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-87-6db3730dc7c8>\u001b[0m in \u001b[0;36mmy_load_data\u001b[0;34m(test_size)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# split the data to training and testing and return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2120\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2121\u001b[0m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[0;32m-> 2122\u001b[0;31m                                               default_test_size=0.25)\n\u001b[0m\u001b[1;32m   2123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   1803\u001b[0m             \u001b[0;34m'resulting train set will be empty. Adjust any of the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m             'aforementioned parameters.'.format(n_samples, test_size,\n\u001b[0;32m-> 1805\u001b[0;31m                                                 train_size)\n\u001b[0m\u001b[1;32m   1806\u001b[0m         )\n\u001b[1;32m   1807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=1, test_size=0.9 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCX_scCQJh5o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e87ecd75-f613-412d-9280-c106559e18b7"
      },
      "source": [
        "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 81.25%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtirQv0HJkQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isdir(\"result\"):\n",
        "    os.mkdir(\"result\")\n",
        "\n",
        "pickle.dump(model, open(\"result/mlp_classifier.model\", \"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Pbdf408a0wA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "d3444847-ce7f-45eb-cd5d-5a094ece1bef"
      },
      "source": [
        "# !apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
        "pip install pyaudio"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyaudio\n",
            "  Using cached https://files.pythonhosted.org/packages/ab/42/b4f04721c5c5bfc196ce156b3c768998ef8c0ae3654ed29ea5020c749a6b/PyAudio-0.2.11.tar.gz\n",
            "Building wheels for collected packages: pyaudio\n",
            "  Building wheel for pyaudio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyaudio: filename=PyAudio-0.2.11-cp36-cp36m-linux_x86_64.whl size=51621 sha256=d39d0436e006ca3b05c82f824c361bf7d4d9a7d78de518d88a6ef82b50c9b8d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/a8/a4/292214166c2917890f85b2f72a8e5f13e1ffa527c4200dcede\n",
            "Successfully built pyaudio\n",
            "Installing collected packages: pyaudio\n",
            "Successfully installed pyaudio-0.2.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDWnJgCIJoF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pyaudio\n",
        "import wave\n",
        "from sys import byteorder\n",
        "from array import array\n",
        "from struct import pack\n",
        "from sklearn.neural_network import MLPClassifier\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pvfze1C0LG7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "THRESHOLD = 500\n",
        "CHUNK_SIZE = 1024\n",
        "FORMAT = pyaudio.paInt16\n",
        "RATE = 16000\n",
        "SILENCE = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLrINDBvLI-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_silent(snd_data):\n",
        "    \"Returns 'True' if below the 'silent' threshold\"\n",
        "    return max(snd_data) < THRESHOLD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3chau2OLQTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(snd_data):\n",
        "    \"Average the volume out\"\n",
        "    MAXIMUM = 16384\n",
        "    times = float(MAXIMUM)/max(abs(i) for i in snd_data)\n",
        "\n",
        "    r = array('h')\n",
        "    for i in snd_data:\n",
        "        r.append(int(i*times))\n",
        "    return r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm_qP7nlLT8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trim(snd_data):\n",
        "    \"Trim the blank spots at the start and end\"\n",
        "    def _trim(snd_data):\n",
        "        snd_started = False\n",
        "        r = array('h')\n",
        "\n",
        "        for i in snd_data:\n",
        "            if not snd_started and abs(i)>THRESHOLD:\n",
        "                snd_started = True\n",
        "                r.append(i)\n",
        "\n",
        "            elif snd_started:\n",
        "                r.append(i)\n",
        "        return r\n",
        "\n",
        "    # Trim to the left\n",
        "    snd_data = _trim(snd_data)\n",
        "\n",
        "    # Trim to the right\n",
        "    snd_data.reverse()\n",
        "    snd_data = _trim(snd_data)\n",
        "    snd_data.reverse()\n",
        "    return snd_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS061V8dLY2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_silence(snd_data, seconds):\n",
        "    \"Add silence to the start and end of 'snd_data' of length 'seconds' (float)\"\n",
        "    r = array('h', [0 for i in range(int(seconds*RATE))])\n",
        "    r.extend(snd_data)\n",
        "    r.extend([0 for i in range(int(seconds*RATE))])\n",
        "    return r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vuy3iE6ZLe41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def record():\n",
        "    \"\"\"\n",
        "    Record a word or words from the microphone and \n",
        "    return the data as an array of signed shorts.\n",
        "    Normalizes the audio, trims silence from the \n",
        "    start and end, and pads with 0.5 seconds of \n",
        "    blank sound to make sure VLC et al can play \n",
        "    it without getting chopped off.\n",
        "    \"\"\"\n",
        "    p = pyaudio.PyAudio()\n",
        "    stream = p.open(format=FORMAT, channels=1, rate=RATE,\n",
        "        input=True, output=True,\n",
        "        frames_per_buffer=CHUNK_SIZE)\n",
        "\n",
        "    num_silent = 0\n",
        "    snd_started = False\n",
        "\n",
        "    r = array('h')\n",
        "\n",
        "    while 1:\n",
        "        # little endian, signed short\n",
        "        snd_data = array('h', stream.read(CHUNK_SIZE))\n",
        "        if byteorder == 'big':\n",
        "            snd_data.byteswap()\n",
        "        r.extend(snd_data)\n",
        "\n",
        "        silent = is_silent(snd_data)\n",
        "\n",
        "        if silent and snd_started:\n",
        "            num_silent += 1\n",
        "        elif not silent and not snd_started:\n",
        "            snd_started = True\n",
        "\n",
        "        if snd_started and num_silent > SILENCE:\n",
        "            break\n",
        "\n",
        "    sample_width = p.get_sample_size(FORMAT)\n",
        "    stream.stop_stream()\n",
        "    stream.close()\n",
        "    p.terminate()\n",
        "\n",
        "    r = normalize(r)\n",
        "    r = trim(r)\n",
        "    r = add_silence(r, 0.5)\n",
        "    return sample_width, r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ONoTqm_LjRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def record_to_file(path):\n",
        "    \"Records from the microphone and outputs the resulting data to 'path'\"\n",
        "    sample_width, data = record()\n",
        "    data = pack('<' + ('h'*len(data)), *data)\n",
        "\n",
        "    wf = wave.open(path, 'wb')\n",
        "    wf.setnchannels(1)\n",
        "    wf.setsampwidth(sample_width)\n",
        "    wf.setframerate(RATE)\n",
        "    wf.writeframes(data)\n",
        "    wf.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIUvl9hWbiDl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "42d33a65-7b82-429b-cf39-d9bea05a7bf6"
      },
      "source": [
        "pip install speechrecognition"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting speechrecognition\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/e1/7f5678cd94ec1234269d23756dbdaa4c8cfaed973412f88ae8adf7893a50/SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8MB 93kB/s \n",
            "\u001b[?25hInstalling collected packages: speechrecognition\n",
            "Successfully installed speechrecognition-3.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1N8714xRGpy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ea7ab43-8c2c-41d7-de74-b2b55a4a45b5"
      },
      "source": [
        "import speech_recognition as sr\n",
        "print(\"hey\")\n",
        "for index, name in enumerate(sr.Microphone.list_microphone_names()):\n",
        "    print(\"hey\")\n",
        "    print(\"Microphone with name \\\"{1}\\\" found for `Microphone(device_index={0})`\".format(index, name))\n",
        "    print(\"i'M OKAY\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hey\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwDpzu0UdMSo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "9d772ea1-6d3c-473d-9c16-7579858e740c"
      },
      "source": [
        "pip install pyalsaaudio"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyalsaaudio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/b6/44871791929d9d7e11325af0b7be711388dfeeab17147988f044a41a6d83/pyalsaaudio-0.8.4.tar.gz (315kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 2.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyalsaaudio\n",
            "  Building wheel for pyalsaaudio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyalsaaudio: filename=pyalsaaudio-0.8.4-cp36-cp36m-linux_x86_64.whl size=57826 sha256=6210b5ef48c5c54f7ed1ea62cef394c54ed34126cbb7a71071125aa1b605c496\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/74/b8/362c8d8e9fefe2fc2a31881c272053eccae6fd22ecd461f672\n",
            "Successfully built pyalsaaudio\n",
            "Installing collected packages: pyalsaaudio\n",
            "Successfully installed pyalsaaudio-0.8.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orJX1hy3Rm_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ctypes import *\n",
        "from contextlib import contextmanager\n",
        "import pyaudio\n",
        "\n",
        "ERROR_HANDLER_FUNC = CFUNCTYPE(None, c_char_p, c_int, c_char_p, c_int, c_char_p)\n",
        "\n",
        "def py_error_handler(filename, line, function, err, fmt):\n",
        "    pass\n",
        "\n",
        "c_error_handler = ERROR_HANDLER_FUNC(py_error_handler)\n",
        "\n",
        "@contextmanager\n",
        "def noalsaerr():\n",
        "    asound = cdll.LoadLibrary('libasound.so')\n",
        "    asound.snd_lib_error_set_handler(c_error_handler)\n",
        "    yield\n",
        "    asound.snd_lib_error_set_handler(None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVQyfaAQPFZ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "543efa6c-2052-4e57-cf5c-6a64e6d7ffc1"
      },
      "source": [
        "pip install playsound pyaudio pydub ffmpeg-python"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting playsound\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/16/10d897b0a83fb4b05b03a63d7a2667ab75f857f67f7062fd447dd3f49bf7/playsound-1.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyaudio in /usr/local/lib/python3.6/dist-packages (0.2.11)\n",
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/79/db/eaf620b73a1eec3c8c6f8f5b0b236a50f9da88ad57802154b7ba7664d0b8/pydub-0.23.1-py2.py3-none-any.whl\n",
            "Collecting ffmpeg-python\n",
            "  Downloading https://files.pythonhosted.org/packages/d7/0c/56be52741f75bad4dc6555991fabd2e07b432d333da82c11ad701123888a/ffmpeg_python-0.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from ffmpeg-python) (0.16.0)\n",
            "Installing collected packages: playsound, pydub, ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0 playsound-1.2.2 pydub-0.23.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFUuWMOmj9t0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "71329b0d-3d4f-4016-a5fd-12fa27c64ec2"
      },
      "source": [
        "!pip install -q https://github.com/pyannote/pyannote-audio/tarball/develop"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for pyannote.audio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: chainer 6.5.0 has requirement typing-extensions<=3.6.6, but you'll have typing-extensions 3.7.4.2 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb3E61nukVNG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "1f5da051-549d-4f39-f406-ffc424a8544c"
      },
      "source": [
        "pip install typing-extensions==3.6.6"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting typing-extensions==3.6.6\n",
            "  Downloading https://files.pythonhosted.org/packages/62/4f/392a1fa2873e646f5990eb6f956e662d8a235ab474450c72487745f67276/typing_extensions-3.6.6-py3-none-any.whl\n",
            "\u001b[31mERROR: pyannote-core 3.7.1 has requirement typing-extensions>=3.7.4.1, but you'll have typing-extensions 3.6.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pyannote-audio 0+unknown has requirement typing-extensions>=3.7.4, but you'll have typing-extensions 3.6.6 which is incompatible.\u001b[0m\n",
            "Installing collected packages: typing-extensions\n",
            "  Found existing installation: typing-extensions 3.7.4.2\n",
            "    Uninstalling typing-extensions-3.7.4.2:\n",
            "      Successfully uninstalled typing-extensions-3.7.4.2\n",
            "Successfully installed typing-extensions-3.6.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYDQeOApLnfG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "b226caa1-5248-42ce-a58c-b15f7ae35876"
      },
      "source": [
        "from pyannote.audio.features import RawAudio\n",
        "from IPython.display import Audio\n",
        "from scipy.io import wavfile\n",
        "import wave\n",
        "from scipy.io import wavfile\n",
        "from pyannote.core import Segment, notebook\n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    \n",
        "    # make notebook visualization zoom on 600s < t < 660s time range\n",
        "    EXCERPT = Segment(0, 5)\n",
        "    # load the saved model (after training)\n",
        "    model = pickle.load(open(\"result/mlp_classifier.model\", \"rb\"))\n",
        "    print(\"Please talk\")\n",
        "    filename = \"test.wav\"\n",
        "    print(\"Recording...\")\n",
        "    audio, sr = get_audio()\n",
        "    \n",
        "\n",
        "# load audio waveform, crop excerpt, and play it\n",
        "    DEMO_FILE = {'uri': 'output.wav', 'audio': audio}\n",
        "    waveform = RawAudio(sample_rate=16000).crop(DEMO_FILE,EXCERPT)\n",
        "    # Audio(data=waveform.squeeze(), rate=16000, autoplay=True)\n",
        "    demo_new = wavfile.write('result.wav',16000,waveform)\n",
        "    Audio(data=waveform.squeeze,filename ='result.wav',rate=16000,autoplay=True)\n",
        "    print(demo_new)\n",
        "    \n",
        "# THRESHOLD = 500\n",
        "# CHUNK_SIZE = 1024\n",
        "# FORMAT = pyaudio.paInt16\n",
        "# RATE = 16000\n",
        "# SILENCE = 30\n",
        "    # channels =1\n",
        "    # record_seconds =5\n",
        "    # with noalsaerr():\n",
        "    #   p= pyaudio.PyAudio()\n",
        "    \n",
        "    # print(p.get_default_input_device_info())\n",
        "    # print(p.get_device_count())\n",
        "    # stream = p.open(format=FORMAT,\n",
        "    #             channels=channels,\n",
        "    #             rate=RATE,\n",
        "    #             input=True,\n",
        "    #             output=True,\n",
        "    #             frames_per_buffer=CHUNK_SIZE)\n",
        "    # stream.read()\n",
        "    # frames = []\n",
        "    # print(\"Recording...\")\n",
        "    # for i in range(int(44100 / chunk * record_seconds)):\n",
        "    #   data = stream.read(chunk)\n",
        "    #   # if you want to hear your voice while recording\n",
        "    #   # stream.write(data)\n",
        "    #   frames.append(data)\n",
        "    # print(\"Finished recording.\")\n",
        "    # # stop and close stream\n",
        "    # stream.stop_stream()\n",
        "    # stream.close()\n",
        "    # # terminate pyaudio object\n",
        "    # p.terminate()\n",
        "    # # save audio file\n",
        "    # # open the file in 'write bytes' mode\n",
        "    # wf = wave.open(filename, \"wb\")\n",
        "    # # set the channels\n",
        "    # wf.setnchannels(channels)\n",
        "    # # set the sample format\n",
        "    # wf.setsampwidth(p.get_sample_size(FORMAT))\n",
        "    # # set the sample rate\n",
        "    # wf.setframerate(sample_rate)\n",
        "    # # write the frames as bytes\n",
        "    # wf.writeframes(b\"\".join(frames))\n",
        "    # # close the file\n",
        "    # wf.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # # record the file (start talking)\n",
        "    # record_to_file(filename)\n",
        "    # # extract features and reshape it\n",
        "    # features = extract_feature(filename, mfcc=True, chroma=True, mel=True).reshape(1, -1)\n",
        "    # # predict\n",
        "    # result = model.predict(features)[0]\n",
        "    # # show the result !\n",
        "    # print(\"result:\", result)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please talk\n",
            "Recording...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_p = document.createElement(\"P\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"Press to start recording\");\n",
              "\n",
              "my_btn.appendChild(t);\n",
              "//my_p.appendChild(my_btn);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  var options = {\n",
              "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
              "    mimeType : 'audio/webm;codecs=opus'\n",
              "    //mimeType : 'audio/webm;codecs=pcm'\n",
              "  };            \n",
              "  //recorder = new MediaRecorder(stream, options);\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {            \n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('audio');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data); \n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "      //console.log(\"Inside FileReader:\" + base64data);\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "  };\n",
              "\n",
              "recordButton.innerText = \"Recording... press to stop\";\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
              "  }\n",
              "}\n",
              "\n",
              "// https://stackoverflow.com/a/951057\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "//recordButton.addEventListener(\"click\", toggleRecording);\n",
              "recordButton.onclick = ()=>{\n",
              "toggleRecording()\n",
              "\n",
              "sleep(2000).then(() => {\n",
              "  // wait 2000ms for the data to be available...\n",
              "  // ideally this should use something like await...\n",
              "  //console.log(\"Inside data:\" + base64data)\n",
              "  resolve(base64data.toString())\n",
              "\n",
              "});\n",
              "\n",
              "}\n",
              "});\n",
              "      \n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-cda8992e9eaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# load audio waveform, crop excerpt, and play it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mDEMO_FILE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'uri'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'output.wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'audio'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mwaveform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRawAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEMO_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEXCERPT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Audio(data=waveform.squeeze(), rate=16000, autoplay=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mdemo_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwavfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'result.wav'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwaveform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyannote/audio/features/utils.py\u001b[0m in \u001b[0;36mcrop\u001b[0;34m(self, current_file, segment, mode, fixed)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;31m# read file with SoundFile, which supports various fomats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;31m# including NIST sphere\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"audio\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    627\u001b[0m         self._info = _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    628\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0;31m# Move write position to 0 (like in Python file objects)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1180\u001b[0m                                             mode_int, self._info, _ffi.NULL)\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid file: {0!r}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m         _error_check(_snd.sf_error(file_ptr),\n\u001b[1;32m   1184\u001b[0m                      \"Error opening {0!r}: \".format(self.name))\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid file: array([ 0,  0,  0, ..., 89, 89, 74], dtype=int16)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4titu2ffHjx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "4bc9b2f0-5d89-449a-b368-397e7b1919fb"
      },
      "source": [
        "!pip install ffmpeg-python"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from ffmpeg-python) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hx3lZjv0ePq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "To write this piece of code I took inspiration/code from a lot of places.\n",
        "It was late night, so I'm not sure how much I created or just copied o.O\n",
        "Here are some of the possible references:\n",
        "https://blog.addpipe.com/recording-audio-in-the-browser-using-pure-html5-and-minimal-javascript/\n",
        "https://stackoverflow.com/a/18650249\n",
        "https://hacks.mozilla.org/2014/06/easy-audio-capture-with-the-mediarecorder-api/\n",
        "https://air.ghost.io/recording-to-an-audio-file-using-html5-and-js/\n",
        "https://stackoverflow.com/a/49019356\n",
        "\"\"\"\n",
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };            \n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {            \n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data); \n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      //console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
        "  }\n",
        "}\n",
        "\n",
        "// https://stackoverflow.com/a/951057\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "//recordButton.addEventListener(\"click\", toggleRecording);\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "\n",
        "sleep(2000).then(() => {\n",
        "  // wait 2000ms for the data to be available...\n",
        "  // ideally this should use something like await...\n",
        "  //console.log(\"Inside data:\" + base64data)\n",
        "  resolve(base64data.toString())\n",
        "\n",
        "});\n",
        "\n",
        "}\n",
        "});\n",
        "      \n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  \n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "  \n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  return audio, sr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laBC1GFHeTfd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "85fdb33b-e511-44ea-8646-7a651e572695"
      },
      "source": [
        "audio, sr = get_audio()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_p = document.createElement(\"P\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"Press to start recording\");\n",
              "\n",
              "my_btn.appendChild(t);\n",
              "//my_p.appendChild(my_btn);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var reader;\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  var options = {\n",
              "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
              "    mimeType : 'audio/webm;codecs=opus'\n",
              "    //mimeType : 'audio/webm;codecs=pcm'\n",
              "  };            \n",
              "  //recorder = new MediaRecorder(stream, options);\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {            \n",
              "    var url = URL.createObjectURL(e.data);\n",
              "    var preview = document.createElement('audio');\n",
              "    preview.controls = true;\n",
              "    preview.src = url;\n",
              "    document.body.appendChild(preview);\n",
              "\n",
              "    reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data); \n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "      //console.log(\"Inside FileReader:\" + base64data);\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "  };\n",
              "\n",
              "recordButton.innerText = \"Recording... press to stop\";\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "\n",
              "\n",
              "function toggleRecording() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
              "  }\n",
              "}\n",
              "\n",
              "// https://stackoverflow.com/a/951057\n",
              "function sleep(ms) {\n",
              "  return new Promise(resolve => setTimeout(resolve, ms));\n",
              "}\n",
              "\n",
              "var data = new Promise(resolve=>{\n",
              "//recordButton.addEventListener(\"click\", toggleRecording);\n",
              "recordButton.onclick = ()=>{\n",
              "toggleRecording()\n",
              "\n",
              "sleep(2000).then(() => {\n",
              "  // wait 2000ms for the data to be available...\n",
              "  // ideally this should use something like await...\n",
              "  //console.log(\"Inside data:\" + base64data)\n",
              "  resolve(base64data.toString())\n",
              "\n",
              "});\n",
              "\n",
              "}\n",
              "});\n",
              "      \n",
              "</script>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}